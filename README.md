# Paper Notebook

This repository serves as my personal notebook, collecting papers of interest that I encounter anytime, anywhere.

## Table of Contents

- [Surface Reconstruction](#Surface-Reconstruction)
- [Unclassified](#3dgs-based-3d-reconstruction)


## Surface Reconstruction

- ★ "MVSNet: Depth Inference for Unstructured Multi-view Stereo." ECCV (2018). [[Paper](https://arxiv.org/pdf/1804.02505)] [[Code](https://github.com/xy-guo/MVSNet_pytorch)][[note]()]
- ☆ "FatesGS: Fast and Accurate Sparse-View Surface Reconstruction using Gaussian Splatting with Depth-Feature Consistency." AAAI (2025). [[Paper](https://arxiv.org/pdf/2501.04628)] [[Code](https://github.com/yulunwu0108/FatesGS)]
- 


<details>
<summary><b>:book: Follow-up Papers</b></summary>
  
> Since MVS has been studied for many years, we continue to update papers based on previous repo.

#### Before Papers  
- **Link:** [Awesome-MVS](https://github.com/walsvid/Awesome-MVS)

#### ICG-MVSNet: Learning Intra-view and Cross-view Relationships for Guidance in Multi-View Stereo
- **Publication:** ICME 2025
- **Link:** [Paper](https://arxiv.org/pdf/2503.21525) | [Code](https://github.com/YuhsiHu/ICG-MVSNet)

</details>

## NeRF-based 3D Reconstruction

#### :star2: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
- **Publication:** ECCV 2020 (Oral)
- **Link:** [Paper](https://arxiv.org/pdf/2003.08934) | [Project Page](https://www.matthewtancik.com/nerf) | [Code](https://github.com/bmild/nerf)

<details>
<summary><b>:book: Follow-up Papers</b></summary>
  


</details>

## NeuS-based 3D Reconstruction

#### :star2: NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction
- **Publication:** NeurIPS 2021 (Spotlight)
- **Link:** [Paper](https://arxiv.org/pdf/2106.10689) | [Project Page](https://lingjie0206.github.io/papers/NeuS/) | [Code](https://github.com/Totoro97/NeuS)

<details>
<summary><b>:book: Follow-up Papers</b></summary>

</details>

## 3DGS-based 3D Reconstruction

#### :star2: 3D Gaussian Splatting for Real-Time Radiance Field Rendering
- **Publication:** SIGGRAPH 2023
- **Link:** [Paper](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/3d_gaussian_splatting_high.pdf) | [Project Page](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/) | [Code](https://github.com/graphdeco-inria/gaussian-splatting)


<details>
<summary><b>:book: Follow-up Papers</b></summary>
  
#### 2D Gaussian Splatting for Geometrically Accurate Radiance Fields 
- **Publication:** SIGGRAPH 2024
- **Link:** [Paper](https://arxiv.org/pdf/2403.17888) | [Code](https://github.com/hbb1/2d-gaussian-splatting) | [Project Page](https://surfsplatting.github.io/)

#### Gaussian Opacity Fields: Efficient Adaptive Surface Reconstruction in Unbounded Scenes  
- **Publication:** SIGGRAPH Asia 2024
- **Link:** [Paper](https://arxiv.org/pdf/2404.10772) | [Code](https://github.com/autonomousvision/gaussian-opacity-fields) | [Project Page](https://niujinshuchong.github.io/gaussian-opacity-fields/)

#### RaDe-GS: Rasterizing Depth in Gaussian Splatting 
- **Publication:** ArXiv 2024
- **Link:** [Paper](https://arxiv.org/pdf/2406.01467) | [Code](https://github.com/BaowenZ/RaDe-GS) | [Project Page](https://baowenz.github.io/radegs/)

#### PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction 
- **Publication:** TVCG 2024
- **Link:** [Paper](https://arxiv.org/pdf/2406.06521) | [Code](https://github.com/zju3dv/PGSR) | [Project Page](https://zju3dv.github.io/pgsr/)

<details>
